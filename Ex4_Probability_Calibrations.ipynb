{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4.1\n",
    "***\n",
    "Using the data file found here: https://alien.usm.uni-muenchen.de/SDSS/specPhotoDR12v3 hoyleb extcorr clean1e5.fit ,Construct an input array of model magnitudes and colors. Construct a\n",
    "target array using the column name SPEC CLASS ID. Note that the object\n",
    "types are shown in the column SPEC CLASS and correspond to Stars, Galaxies\n",
    "and Quasars. Remove all of the Quasars.\n",
    "\n",
    "Split the data set into a training, test, and validation samples of size (60%,\n",
    "20%, 20%). Train a Random Forest classifier to perform star galaxy separation.\n",
    "Make probability predictions for the star class, on the validation data and\n",
    "make a reliability curve diagram.\n",
    "Use the sklearn calibration classifier trained on the \n",
    "1.  the validation data\n",
    "2.  the training data\n",
    "to calibrate the output of the trained machine.\n",
    "\n",
    "## Problem 4.2\n",
    "***\n",
    "Make probabilistic predictions on the test data, and calibrate those probabilities\n",
    "using the trained calibration classifier in both 1.a) and 1.b).\n",
    "Now make the reliability curve diagrams for the test data, and show and\n",
    "label the curves from\n",
    "1) the uncalibrated probabilities,\n",
    "2) those calibrated in 1.a)\n",
    "3) those calibrated in 1.b)\n",
    "\n",
    "## Problem 4.3\n",
    "***\n",
    "Compare the F1 (from sklearn.metrics) scores as measured on the test sample\n",
    "on all of the calibrated and calibrated predictions\n",
    "Describe your results with at least 100 words.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4.1\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =Table.read('specPhotoDR12v3_hoyleb_extcorr_clean1e5.fit')\n",
    "#removing quasar\n",
    "dataset_woq=dataset[dataset[\"SPEC_CLASS\"] != \"QSO   \"]\n",
    "\n",
    "#######defining target \n",
    "target =dataset_woq[\"SPEC_CLASS\"]\n",
    "\n",
    "########defining feature\n",
    "# we use dereddend magnitudes \n",
    "color = ['DERED_U', 'DERED_G', 'DERED_R','DERED_I','DERED_Z']\n",
    "\n",
    "#and color combinations created from them.\n",
    "comb= []\n",
    "for i in range(len(color)):\n",
    "    for j in range(i, len(color)):\n",
    "       comb.append(color[i]+'-' + color[j])\n",
    "\n",
    "# determining value for each color comb\n",
    "inputs = np.zeros((len(dataset_woq), len(color+comb)), dtype=np.float64) #initiate zero array of size (number of rows x length(mag+col_comb))\n",
    "for i, key in enumerate(color):\n",
    "    inputs[:, i] = np.array(dataset_woq[key])\n",
    "\n",
    "comb_ind = len(color)\n",
    "for i in range(len(color)):\n",
    "    for j in range(i, len(color)):\n",
    "        inputs[:, comb_ind] = np.array(dataset_woq[color[i]] - dataset_woq[color[j]])\n",
    "        comb_ind += 1\n",
    "\n",
    "#feature column\n",
    "features=color+comb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#create panda dataframe \n",
    "df_input=pd.DataFrame(inputs, columns=features)\n",
    "df_input=df_input.drop([\"DERED_U-DERED_U\",\"DERED_G-DERED_G\", \"DERED_R-DERED_R\", \n",
    "                        \"DERED_I-DERED_I\", \"DERED_Z-DERED_Z\"], axis=1)\n",
    "\n",
    "le=LabelEncoder()\n",
    "df_target =pd.DataFrame({\" Object Type\": le.fit_transform(target)})\n",
    "\n",
    "X_train_cv , X_test, y_train_cv, y_test=train_test_split(df_input, df_target, test_size=0.2)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train_cv, y_train_cv, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khoirul_muzakka/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/khoirul_muzakka/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest=RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0. ],\n",
       "       [ 0.7,  0.3],\n",
       "       [ 1. ,  0. ],\n",
       "       ..., \n",
       "       [ 1. ,  0. ],\n",
       "       [ 1. ,  0. ],\n",
       "       [ 1. ,  0. ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
