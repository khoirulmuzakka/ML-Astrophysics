{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3-1: Probability Theory\n",
    "***\n",
    "An astronomer has developed a machine learning code that classifies galaxies into three categories: spiral, elliptical, and irregular. This algorithm has a 95 per cent accuracy for spirals, 90 per\n",
    "cent accuracy for ellipticals, and 80 per cent accuracy for irregulars. If a galaxy gets misclassified,\n",
    "the probability for either of the two other classes is equal.\n",
    "The astronomer uses this code to classify galaxies in a sample that consists of 70 per cent spirals,\n",
    "28 per cent ellipticals and 2 per cent irregulars.\n",
    "1. What is the probability that a randomly selected galaxy classified as irregular is actually an\n",
    "irregular?\n",
    "2. What is the probability that a randomly selected galaxy classified as an elliptical is actually\n",
    "a spiral?\n",
    "\n",
    "## Exercise 3-2 Gradient descent\n",
    "***\n",
    "Here, we want to test how well gradient descent does for several test problems. For this, use three\n",
    "different functions, both in 2 and 30 dimensions:\n",
    "-  Sphere function\n",
    "-  Rosenbrock function\n",
    "-  Rastrigin function\n",
    "\n",
    "You can find the analytic descriptions here:\n",
    "https://en.wikipedia.org/wiki/Test_functions_for_optimization\n",
    "1. Implement a gradient optimizer\n",
    "To test your algorithm with each function, you will need to calculate the gradient for each of the\n",
    "above functions. Use a default learning rate of Î· = 0.1.\n",
    "2. Test your gradient optimizer on all three functions for 2 dimensions\n",
    "How many iterations do you need to achieve an accuracy of 1.e-5? How do you have to adjust\n",
    "your learning rate for each test function? Why?\n",
    "3. Plot the function value vs the number of iterations\n",
    "4. Test your gradient optimizer on all three functions for 30 dimensions\n",
    "Here, we want to test how well gradient descent does for several test problems. For this, use three\n",
    "different functions, both in 2 and 30 dimensions.\n",
    "\n",
    "## Exercise 3-3 Monte Carlo optimizers\n",
    "***\n",
    "Here, we want to test how well Monte Carlo methods do for several test problems. Use the same\n",
    "test functions as in 3-2.\n",
    "1.  Implement a Metropolis Hastings MCMC algorithm\n",
    "2.  Test your MCMC on all three functions for 2 dimensions\n",
    "How many iterations do you need to achieve an accuracy of 1.e-5? How do you have to adjust\n",
    "your learning rate for each test function? Why? How about 30 dimensions?\n",
    "3.  Plot the function value vs the number of iterations and the 1st vs 2nd dimension for each\n",
    "step\n",
    "4.  Bonus questions: Try other stochastic methods, e.g.\n",
    "-   Affine invariant ensemble sampler http://dfm.io/emcee\n",
    "-   Parallel tempering http://dfm.io/emcee\n",
    "-   Genetic algorithms https://github.com/deap/deap\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test function\n",
    "1. Shperical Function. \n",
    "\n",
    "The function is given by $f(x)= \\sum_i x_i^2$ and the Gradient is given by $ f^{(i)}(x)=2x_j$\n",
    "2. Rosenbrock Function. According to [Wikipedia](https://en.wikipedia.org/wiki/Test_functions_for_optimization), The Rosenbrock function in $N$-dimension is given by\n",
    "$$f(x) = \\sum_{i=1}^{N-1} \\left[100 (x_{i+1}-x_i^2)^2+(1-x_i)^2\\right]$$\n",
    "The derivative is then given by \n",
    "$$\\frac{\\partial f}{\\partial x_j} = \\sum_{i=1}^{N-1} \\left[ 2(x_{i+1}-x_{i}^2) \\delta_{j(i+1)}-2\\left[2x_{i+1} x_{i} -2x_{i}^3-x_{i}+1\\right]\\delta_{ji}\\right]\\\\\n",
    "= 4x_j^3-4x_j x_{j+1}-2x_{j-1}^2+4x_j-2$$\n",
    "\n",
    "3. Rastrigin Function. The function is given by \n",
    "$$ f(x) = 10 N \\sum_i^N \\left[ x_i^2- 10\\cos (2\\pi x_i)\\right]$$\n",
    "\n",
    "and the derivativ is given by\n",
    "$$\\frac{\\partial f}{\\partial x_j} = 20N\\left(x_j+10\\pi\\sin(2\\pi x_j)\\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import scipy as sc\n",
    "from scipy import spatial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Gradient Descent\n",
    "***\n",
    "### Spherical Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iteration : 161\n",
      "Minimum value: [2.49739884e-16 2.49739884e-16]\n"
     ]
    }
   ],
   "source": [
    "########## 2 DImensions ##############\n",
    "\n",
    "#Pick initial Vector \n",
    "x=np.array([1,1])\n",
    "\n",
    "#Learning rate\n",
    "a=0.1\n",
    "\n",
    "#initial updated value\n",
    "x_up =x\n",
    "\n",
    "#update and looping\n",
    "it  = 0\n",
    "while True:\n",
    "    try :\n",
    "        it = it+1\n",
    "        x =x_up\n",
    "        x_up = 0.8*x\n",
    "        if spatial.distance.euclidean(x,x_up) < 0.0000000000000001:\n",
    "            print (\"number of iteration : {}\".format(it))\n",
    "            print (\"Minimum value: {}\".format(x_up))\n",
    "            break\n",
    "    except ValueError:\n",
    "        print(\"overflow happens at {} iteration\".format(it))\n",
    "        break\n",
    "    except KeyboardInterrupt :\n",
    "        print (\"number of iteration so far: {}\".format(it))\n",
    "        print (\"Minimum value so far: {}\".format(x_up))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iteration : 43\n",
      "Minimum value: [6.80564734e-05 6.80564734e-05 6.80564734e-05 6.80564734e-05\n",
      " 6.80564734e-05 6.80564734e-05 6.80564734e-05 6.80564734e-05\n",
      " 6.80564734e-05 6.80564734e-05 6.80564734e-05 6.80564734e-05\n",
      " 6.80564734e-05 6.80564734e-05 6.80564734e-05 6.80564734e-05\n",
      " 6.80564734e-05 6.80564734e-05 6.80564734e-05 6.80564734e-05\n",
      " 6.80564734e-05 6.80564734e-05 6.80564734e-05 6.80564734e-05\n",
      " 6.80564734e-05 6.80564734e-05 6.80564734e-05 6.80564734e-05\n",
      " 6.80564734e-05 6.80564734e-05]\n"
     ]
    }
   ],
   "source": [
    "#Pick initial Vector \n",
    "x=np.ones((30,))\n",
    "\n",
    "#Learning rate\n",
    "a=0.000000001\n",
    "\n",
    "#initial updated value\n",
    "x_up =x\n",
    "\n",
    "#update and looping\n",
    "it  = 0\n",
    "\n",
    "while True:\n",
    "    try : \n",
    "        it = it+1\n",
    "        x =x_up\n",
    "        x_up = 0.8*x\n",
    "        if spatial.distance.euclidean(x,x_up) < 0.0001:\n",
    "            print (\"number of iteration : {}\".format(it))\n",
    "            print (\"Minimum value: {}\".format(x_up))\n",
    "            break\n",
    "    except ValueError:\n",
    "        print(\"overflow happens at {} iteration\".format(it))\n",
    "        break\n",
    "    except KeyboardInterrupt :\n",
    "        print (\"number of iteration so far: {}\".format(it))\n",
    "        print (\"Minimum value so far: {}\".format(x_up))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rosenbrock Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kronecker(i,j):\n",
    "    if i==j:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "def der_f (x,j,N) :\n",
    "    \"\"\"Derivative of Rosenbrock function with repect to x_j, with j=1,2,..., N \"\"\"\n",
    "    if j==N :\n",
    "        return 4*x[N-1]**3-2*x[N-2]**2+4*x[N-1]-2\n",
    "    elif j==1 :\n",
    "        return 4*x[0]**3-4*x[0]*x[1]+4*x[0]-2\n",
    "    else :\n",
    "        return 4*x[j-1]**3-4*x[j-1]*x[j]-2*x[j-2]**2+4*x[j-1]-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iteration : 1\n",
      "Minimum value: [2.99999994 4.9999995 ]\n"
     ]
    }
   ],
   "source": [
    "###################### 2 Dimensions#######################\n",
    "#Pick initial Vector \n",
    "x=np.array([3,5])\n",
    "\n",
    "#Learning rate\n",
    "a=0.000000001  #\n",
    "\n",
    "#initial updated value\n",
    "x_up =x\n",
    "\n",
    "#update and looping\n",
    "it  = 0\n",
    "\n",
    "while True:\n",
    "    try :\n",
    "        it = it+1\n",
    "        x =x_up\n",
    "        x_up = x - a*np.array([der_f(x, j, 2) for j in range(1,3)])   \n",
    "        if spatial.distance.euclidean(x,x_up) < 0.0001:\n",
    "            print (\"number of iteration : {}\".format(it))\n",
    "            print (\"Minimum value: {}\".format(x_up))\n",
    "            break\n",
    "    except ValueError:\n",
    "        print(\"overflow happens at {} iteration\".format(it))\n",
    "        break\n",
    "    except KeyboardInterrupt :\n",
    "        print (\"number of iteration so far: {}\".format(it))\n",
    "        print (\"Minimum value so far: {}\".format(x_up))\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iteration : 430016\n",
      "Minimum value: [1.03712334 1.59593214 1.86742512 1.99892244 2.06662354 2.10431282\n",
      " 2.12692448 2.14139094 2.15114967 2.15802319 2.16303875 2.16680714\n",
      " 2.16970861 2.17198936 2.17381425 2.17529696 2.17651789 2.17753518\n",
      " 2.17839168 2.17911955 2.17974332 2.18028191 2.18075014 2.1811595\n",
      " 2.18151593 2.18178471 2.18151178 2.17635525 2.13137912 1.81342158]\n"
     ]
    }
   ],
   "source": [
    "############ B.2 30 Dimension #################\n",
    "\n",
    "#Pick initial Vector \n",
    "x=np.array([i for i in range(1,31)])\n",
    "\n",
    "#Learning rate\n",
    "a=0.0000001  #\n",
    "\n",
    "#initial updated value\n",
    "x_up =x\n",
    "\n",
    "#update and looping\n",
    "it  = 0\n",
    "\n",
    "while True:\n",
    "    try :\n",
    "        it = it+1\n",
    "        x =x_up\n",
    "        x_up = x - a*np.array([der_f(x, j, 30) for j in range(1,31)]) \n",
    "        if spatial.distance.euclidean(x,x_up) < 0.00001:\n",
    "            print (\"number of iteration : {}\".format(it))\n",
    "            print (\"Minimum value: {}\".format(x_up))\n",
    "            break\n",
    "    except ValueError:\n",
    "        print(\"overflow happens at {} iteration\".format(it))\n",
    "        break\n",
    "    except KeyboardInterrupt :\n",
    "        print (\"number of iteration so far: {}\".format(it))\n",
    "        print (\"Minimum value so far: {}\".format(x_up))\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastrigin Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iteration : 1\n",
      "Minimum value: [0.99999996 5.99999976]\n"
     ]
    }
   ],
   "source": [
    "#Gradient Vector :\n",
    "def grad_f(x, N) :\n",
    "    return np.array([20*N*(x[j-1]+10*np.pi* np.sin(2*np.pi*x[j-1])) for j in range(1, N+1)])\n",
    "\n",
    "#################### 2 Dimensions #################\n",
    "\n",
    "#Pick initial Vector \n",
    "x=np.array([1,6])\n",
    "\n",
    "#Learning rate\n",
    "a=0.000000001\n",
    "\n",
    "#initial updated value\n",
    "x_up =x\n",
    "\n",
    "#update and looping\n",
    "it  = 0\n",
    "while True:\n",
    "    try :\n",
    "        it = it+1\n",
    "        x =x_up\n",
    "        x_up = x-a*grad_f(x, 2)\n",
    "        if spatial.distance.euclidean(x,x_up) < 0.0001:\n",
    "            print (\"number of iteration : {}\".format(it))\n",
    "            print (\"Minimum value: {}\".format(x_up))\n",
    "            break\n",
    "    except ValueError:\n",
    "        print(\"overflow happens at {} iteration\".format(it))\n",
    "        break\n",
    "    except KeyboardInterrupt :\n",
    "        print (\"number of iteration so far: {}\".format(it))\n",
    "        print (\"Minimum value so far: {}\".format(x_up))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iteration : 1\n",
      "Minimum value: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]\n"
     ]
    }
   ],
   "source": [
    "################### 30 Dimensions ####################\n",
    "\n",
    "#Gradient Vector :\n",
    "def grad_f(x, N) :\n",
    "    return np.array([20*N*(x[j-1]+10*np.pi* np.sin(2*np.pi*x[j-1])) for j in range(1, N+1)])\n",
    "\n",
    "#Pick initial Vector \n",
    "x=np.array([i for i in range(1,31)])\n",
    "\n",
    "#Learning rate\n",
    "a=0.000000000000001\n",
    "\n",
    "#initial updated value\n",
    "x_up =x\n",
    "\n",
    "#update and looping\n",
    "it  = 0\n",
    "while True:\n",
    "    try :\n",
    "        it = it+1\n",
    "        x =x_up\n",
    "        x_up = x-a*grad_f(x, 30)\n",
    "        if spatial.distance.euclidean(x,x_up) < 0.0001:\n",
    "            print (\"number of iteration : {}\".format(it))\n",
    "            print (\"Minimum value: {}\".format(x_up))\n",
    "            break\n",
    "    except ValueError:\n",
    "        print(\"overflow happens at {} iteration\".format(it))\n",
    "        break\n",
    "    except KeyboardInterrupt :\n",
    "        print (\"number of iteration so far: {}\".format(it))\n",
    "        print (\"Minimum value so far: {}\".format(x_up))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.3 Montecarlo Optimizer\n",
    "***\n",
    "### Sphericle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(x, N) :\n",
    "    return np.exp(-sum([x[i-1]**2 for i in range(1, N+1)]))\n",
    "prob(np.array([0]),1)\n",
    "\n",
    "################### 2 Dimensions#############\n",
    "#choose initial value of x\n",
    "x=np.array([1])\n",
    "x_up = x\n",
    "it = 0\n",
    "axis_x = []\n",
    "#axis_y =[]\n",
    "\n",
    "#choose Gaussian as proposal distribution\n",
    "#choose initial value of x\n",
    "x=np.array([1,1])\n",
    "x_up = x\n",
    "it = 0\n",
    "axis_x = []\n",
    "axis_y =[]\n",
    "\n",
    "#choose Gaussian as proposal distribution\n",
    "try :\n",
    "    for it in range(0, 300000) :\n",
    "        it = it+1\n",
    "        x = x_up\n",
    "        x_up = np.random.multivariate_normal(x, np.identity(2))\n",
    "        u = np.random.uniform(0.0, 1.0 , 1)\n",
    "        if float(u) < prob(x_up, 2)/ prob(x, 2):\n",
    "            pass\n",
    "        else :\n",
    "            x_up = x\n",
    "            \n",
    "\n",
    "        if it > 100000 :\n",
    "            axis_x.append(x_up[0])\n",
    "            axis_y.append(x_up[1])\n",
    "            \n",
    "except KeyboardInterrupt :\n",
    "    print(it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(axis_x, axis_y, 35)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rosenbrock Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ros(x, N) :\n",
    "    return sum([100*(x[i]-x[i-1]**2)**2+(1-x[i-1])**2   for i in range(1, N)])\n",
    "def prob_ros(x, N) :\n",
    "    return np.exp(-ros(x, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose initial value of x\n",
    "x=np.array([1,1])\n",
    "x_up = x\n",
    "it = 0\n",
    "axis_x = []\n",
    "axis_y =[]\n",
    "\n",
    "#choose Gaussian as proposal distribution\n",
    "try :\n",
    "    for it in range(0, 3000000) :\n",
    "        it = it+1\n",
    "        x = x_up\n",
    "        x_up = np.random.multivariate_normal(x, np.identity(2))\n",
    "        u = np.random.uniform(0.0, 1.0 , 1)\n",
    "        if float(u) < prob_ros(x_up, 2)/ prob_ros(x, 2):\n",
    "            pass\n",
    "        else :\n",
    "            x_up = x\n",
    "            \n",
    "\n",
    "        if it > 2500000 :\n",
    "            axis_x.append(x_up[0])\n",
    "            axis_y.append(x_up[1])\n",
    "            \n",
    "except KeyboardInterrupt :\n",
    "    print(it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(axis_x, axis_y, 35)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rastrigin Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rast(x, N) :\n",
    "    return 10*N*sum([x[i-1]**2-10*np.cos(2*np.pi*x[i-1])  for i in range(1, N+1)])\n",
    "def prob_rast(x, N) :\n",
    "    return np.exp(-rast(x, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose initial value of x\n",
    "x=np.array([1,1])\n",
    "x_up = x\n",
    "it = 0\n",
    "axis_x = []\n",
    "axis_y =[]\n",
    "\n",
    "#choose Gaussian as proposal distribution\n",
    "try :\n",
    "    for it in range(0, 3000000) :\n",
    "        it = it+1\n",
    "        x = x_up\n",
    "        x_up = np.random.multivariate_normal(x, np.identity(2))\n",
    "        u = np.random.uniform(0.0, 1.0 , 1)\n",
    "        if float(u) < prob_rast(x_up, 2)/ prob_rast(x, 2):\n",
    "            pass\n",
    "        else :\n",
    "            x_up = x\n",
    "            \n",
    "\n",
    "        if it > 2500000 :\n",
    "            axis_x.append(x_up[0])\n",
    "            axis_y.append(x_up[1])\n",
    "            \n",
    "except KeyboardInterrupt :\n",
    "    print(it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(axis_x, axis_y, 35)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
